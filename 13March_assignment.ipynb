{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73386014-9c2e-4d00-bdb5-dd505d8c815a",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results. <br>\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical technique used to determine whether there are significant differences between two or more groups of data. There are several assumptions that must be met for ANOVA to be valid. These include:\n",
    "\n",
    "Independence: The observations in each group must be independent of each other.\n",
    "\n",
    "Normality: The data within each group should follow a normal distribution.\n",
    "\n",
    "Homogeneity of variance: The variance within each group should be equal.\n",
    "\n",
    "Random sampling: The data must be randomly selected from the population.\n",
    "\n",
    "If any of these assumptions are violated, the results of ANOVA may not be valid. For example:\n",
    "\n",
    "Independence: If the data is not independent, then the assumption of independence is violated. For example, if a study examines the effect of a drug on patients and the same patients are used for both the treatment and control groups, then the observations are not independent.\n",
    "\n",
    "Normality: If the data is not normally distributed, then the assumption of normality is violated. For example, if a study examines the effect of a drug on blood pressure, and the data is skewed, then the assumption of normality is violated.\n",
    "\n",
    "Homogeneity of variance: If the variance within each group is not equal, then the assumption of homogeneity of variance is violated. For example, if a study examines the effect of a drug on different age groups, and the variance within each group is significantly different, then the assumption of homogeneity of variance is violated.\n",
    "\n",
    "Random sampling: If the data is not randomly selected from the population, then the assumption of random sampling is violated. For example, if a study examines the effect of a drug on a specific group of people who are already known to have a certain condition, then the assumption of random sampling is violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e530354-c5d8-4d77-b15c-df68016b09eb",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used? <br>\n",
    "\n",
    "There are three main types of ANOVA, each used in different situations:\n",
    "\n",
    "One-way ANOVA: This type of ANOVA is used to compare the means of three or more groups that are independent of each other. It is called \"one-way\" because it involves only one independent variable. For example, a one-way ANOVA could be used to compare the mean test scores of students from three different schools.\n",
    "\n",
    "Two-way ANOVA: This type of ANOVA is used to analyze the effect of two independent variables on a single dependent variable. It is called \"two-way\" because it involves two independent variables. For example, a two-way ANOVA could be used to analyze the effect of both age and gender on a certain health condition.\n",
    "\n",
    "Repeated measures ANOVA: This type of ANOVA is used when the same group of participants is measured more than once under different conditions. It is called \"repeated measures\" because the same participants are measured multiple times. For example, a repeated measures ANOVA could be used to analyze the effect of different types of exercise on the heart rate of the same group of individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e276706-90a3-4f92-8220-f30dbdad30c4",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept? <br>\n",
    "\n",
    "In ANOVA (Analysis of Variance), the partitioning of variance refers to the division of the total variance in the data into different sources of variation. Understanding this concept is important because it helps to determine the contribution of different factors to the variation in the data.\n",
    "\n",
    "The partitioning of variance in ANOVA is done into three components:\n",
    "\n",
    "Total Sum of Squares (SST): This is the total amount of variation in the data.\n",
    "\n",
    "Sum of Squares Within Groups (SSW): This is the amount of variation that is due to differences within groups or samples.\n",
    "\n",
    "Sum of Squares Between Groups (SSB): This is the amount of variation that is due to differences between groups or samples.\n",
    "\n",
    "The formula for the partitioning of variance is:\n",
    "\n",
    "SST = SSB + SSW\n",
    "\n",
    "The ratio of SSB to SSW is used to calculate the F statistic, which is used to test the null hypothesis that there is no difference between the means of the groups.\n",
    "\n",
    "Understanding the partitioning of variance is important because it allows researchers to determine which factor(s) are contributing to the variation in the data. This information can be used to identify the most important factors and to design further experiments or interventions that target these factors.\n",
    "\n",
    "Additionally, ANOVA is a powerful statistical technique that is commonly used in many fields, including biology, psychology, economics, and engineering, so understanding the partitioning of variance is crucial for interpreting and communicating the results of ANOVA analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e067c-8a4b-4c2d-a9f0-4539a0a0f072",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python? <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae59f745-00ad-4122-819a-0a5c60d511da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 102.0\n",
      "SSE: 96.0\n",
      "SSR: 6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#create some sample data\n",
    "group1 = [ 4, 6, 5]\n",
    "group2 = [8, 10, 9]\n",
    "group3 = [12, 14, 13]\n",
    "\n",
    "data = np.concatenate([group1,group2,group3])\n",
    "\n",
    "mean = np.mean(data)\n",
    "sst = np.sum((data - mean)**2)\n",
    "\n",
    "sse = ((np.mean(group1)-mean)**2) * len(group1)\n",
    "sse += ((np.mean(group2) - mean) ** 2) * len(group2)\n",
    "sse += ((np.mean(group3) - mean) ** 2) * len(group3)\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print('SST:', sst)\n",
    "print('SSE:', sse)\n",
    "print('SSR:', ssr)\n",
    "\n",
    "#ALTERNATIVELY,\n",
    "# import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.formula.api import ols\n",
    "\n",
    "# # create a DataFrame with your data\n",
    "# df = pd.DataFrame({'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "#                    'value': [4, 6, 5, 8, 10, 9, 12, 14, 13]})\n",
    "\n",
    "# # fit the one-way ANOVA modelza\n",
    "# model = ols('value ~ group', data=df).fit()\n",
    "\n",
    "# # calculate SST\n",
    "# result = sm.stats.anova_lm(model, typ=1)\n",
    "# sse = result.loc[result.index == 'group']['sum_sq'][0]\n",
    "# ssr = result.loc[result.index == 'Residual']['sum_sq'][0]\n",
    "# print(sse)\n",
    "# print(ssr)\n",
    "# sst = ssr+sse\n",
    "# print(sst)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97f0fa-ba0b-4980-b5b5-f98af750c787",
   "metadata": {},
   "source": [
    "Q5.In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71807f64-0090-44e1-b697-523ae3f1f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                df    sum_sq   mean_sq         F    PR(>F)\n",
      "C(Watering)    1.0  0.000369  0.000369  0.000133  0.990865\n",
      "C(Fertilizer)  1.0  0.033333  0.033333  0.012069  0.913305\n",
      "----------------------------------------\n",
      "                            df    sum_sq   mean_sq         F    PR(>F)\n",
      "C(Fertilizer):C(Watering)  1.0  0.040866  0.040866  0.014796  0.904053\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "  \n",
    "# Create a dataframe\n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'height': [14, 16, 15, 15, 16, 13, 12, 11,\n",
    "                                     14, 15, 16, 16, 17, 18, 14, 13, \n",
    "                                     14, 14, 14, 15, 16, 16, 17, 18,\n",
    "                                     14, 13, 14, 14, 14, 15]})\n",
    "  \n",
    "  \n",
    "# Performing two-way ANOVA\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) + \\\n",
    "C(Fertilizer):C(Watering)',data=dataframe).fit()\n",
    "\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "main_effects = result.loc[['C(Watering)','C(Fertilizer)']]\n",
    "print(main_effects)\n",
    "interaction_effects = result.loc[['C(Fertilizer):C(Watering)']]\n",
    "print(\"-\"*40)\n",
    "print(interaction_effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815bf53-9392-443d-9d1a-17595ad4d619",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results? <br>\n",
    "\n",
    "A one-way ANOVA tests the null hypothesis that there is no significant difference between the means of three or more groups. In this case, the obtained F-statistic of 5.23 and a p-value of 0.02 indicates that there is a statistically significant difference between the groups.\n",
    "\n",
    "Specifically, the F-statistic of 5.23 suggests that the variation in the means between the groups is greater than what we would expect due to chance alone. The p-value of 0.02 indicates that the probability of obtaining such a large F-statistic by chance is only 2%, which is below the commonly used threshold of 5% (or 0.05) for statistical significance.\n",
    "\n",
    "Therefore, we can reject the null hypothesis and conclude that there is a significant difference between the means of the groups. However, we cannot determine which specific group(s) differ significantly from the others based on the ANOVA results alone. Post-hoc tests, such as Tukey's HSD or Bonferroni correction, can be conducted to determine the pairwise differences between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5f6c3-3e07-431d-9cd7-eda31b95092f",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data? <br>\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA can be challenging as it requires dealing with missing values across multiple variables. There are several methods to handle missing data, including listwise deletion, pairwise deletion, mean imputation, regression imputation, and multiple imputation.\n",
    "\n",
    "Listwise deletion involves removing any cases with missing data, which can result in a loss of power and biased estimates if the missing data is not missing completely at random (MCAR). Pairwise deletion involves using all available data for each variable, which can lead to biased results if the missing data is not MCAR.\n",
    "\n",
    "Mean imputation involves replacing missing values with the mean value of the available data for that variable. While this method is simple, it can result in biased estimates of the means, standard deviations, and correlations.\n",
    "\n",
    "Regression imputation involves using regression models to estimate the missing values based on the available data. This method can produce unbiased estimates if the imputation model is correctly specified.\n",
    "\n",
    "Multiple imputation involves generating multiple plausible imputed datasets and combining the results to obtain unbiased estimates and standard errors that account for the uncertainty in the imputation process. This method is the most recommended for handling missing data in repeated measures ANOVA.\n",
    "\n",
    "The consequences of using different methods to handle missing data in a repeated measures ANOVA can vary depending on the nature and extent of the missing data, as well as the method used. Using listwise or pairwise deletion can result in biased estimates and a loss of power, while mean imputation can result in biased estimates of means, standard deviations, and correlations. Regression imputation can produce unbiased estimates if the imputation model is correctly specified, but it may not account for the uncertainty in the imputation process. Multiple imputation is the most recommended method as it produces unbiased estimates and standard errors that account for the uncertainty in the imputation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b28062-1844-4c1c-99f7-10a44784fa6a",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary. <br>\n",
    "\n",
    "Post-hoc tests are used after performing ANOVA (Analysis of Variance) to determine the significant differences between pairs of means. Post-hoc tests help to identify which groups differ from one another after finding significant differences between groups in ANOVA. Some commonly used post-hoc tests include:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: This test is commonly used when the sample sizes are equal and when the assumption of homogeneity of variances is met. The Tukey HSD test is considered to be one of the most reliable post-hoc tests because it controls the overall Type I error rate.\n",
    "\n",
    "Bonferroni correction: This test is used to adjust the p-value for multiple comparisons. It is a conservative test that controls the family-wise error rate, making it ideal for situations where a large number of comparisons are being made.\n",
    "\n",
    "Scheffé's test: This test is used when the sample sizes are unequal or when the assumption of homogeneity of variances is violated. It is less powerful than the Tukey HSD test but is more conservative.\n",
    "\n",
    "Dunnett's test: This test is used when comparing several groups to a control group. It is considered to be more powerful than the Bonferroni correction and the Scheffé's test.\n",
    "\n",
    "Example of a situation where a post-hoc test might be necessary:\n",
    "Suppose a researcher wants to investigate whether there are differences in the average exam scores of three different groups of students (Group A, Group B, and Group C). The researcher performs ANOVA and finds that there is a statistically significant difference between the groups. However, the ANOVA does not tell which groups differ from each other. In this case, the researcher needs to perform a post-hoc test to determine which groups are significantly different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97e6cb-12e5-44b0-b647-eb1bfa9eb7b1",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9902b360-a530-4091-bb9a-4260cecd6327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Diet)</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.389464</td>\n",
       "      <td>1.694732</td>\n",
       "      <td>2.673772</td>\n",
       "      <td>0.079476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>47.0</td>\n",
       "      <td>29.790280</td>\n",
       "      <td>0.633836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            df     sum_sq   mean_sq         F    PR(>F)\n",
       "C(Diet)    2.0   3.389464  1.694732  2.673772  0.079476\n",
       "Residual  47.0  29.790280  0.633836       NaN       NaN"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = np.random.normal(5,1,20)\n",
    "b = np.random.normal(5,1.2,15)\n",
    "c = np.random.normal(4.5,0.3,15)\n",
    "\n",
    "weight_loss  = np.concatenate([a,b,c])\n",
    "x = np.array([['A'],['B'],['C']])\n",
    "#np.repeat(x,[20,15,15]) -- repeats a 20 times, b 15 times and c 15 times\n",
    "df1 = pd.DataFrame({'Diet': np.repeat(x,[20,15,15])},\n",
    "                 )\n",
    "df2= pd.DataFrame({'Weight_lost':weight_loss})\n",
    "\n",
    "df = pd.concat([df1,df2],axis=1)\n",
    "model = ols('Weight_lost ~ C(Diet)',data=df).fit()\n",
    "result = sm.stats.anova_lm(model,type=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2d392e-83cd-44e6-82b8-d372ba78be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.6863686425239486\n",
      "p-value: 0.07858248236984498\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "a = np.random.normal(5,1,20)\n",
    "b = np.random.normal(5,1.2,15)\n",
    "c = np.random.normal(4.5,0.3,15)\n",
    "\n",
    "weight_loss  = np.concatenate([a,b,c])\n",
    "# Conduct the one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(a, b, c)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45106af0-37eb-47bc-ad69-efd2fdd1f7fc",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b0daff-83ac-4a7e-aac4-53d1aacbd4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sum_sq    df         F    PR(>F)\n",
      "C(program)                  3.266667   2.0  0.049025  0.952253\n",
      "C(experience)             294.533333   1.0  8.840420  0.006612\n",
      "C(program):C(experience)   30.466667   2.0  0.457229  0.638437\n",
      "Residual                  799.600000  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset with 30 employees\n",
    "df = pd.DataFrame({\n",
    "    'program': ['A', 'B', 'C'] * 10,  # Assign each employee to a program\n",
    "    'experience': ['novice'] * 15 + ['experienced'] * 15,  # Randomly assign experience level\n",
    "    'time': [10, 12, 15, 14, 16, 18, 20, 22, 25, 24, 11, 13, 16, 18, 20,\n",
    "             22, 26, 28, 30, 32, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n",
    "})\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('time ~ C(program) + C(experience) + C(program):C(experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906d4ce-9775-4909-9d9a-7bd9d2879ef1",
   "metadata": {},
   "source": [
    "The ANOVA table shows that there is a significant main effect of experience on task completion time , butc there is no significant main effect of program or interaction effect between program and experience level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cf3b0-2d8d-48cb-af64-c8a18417a220",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7554795-dbfb-4e98-92c5-22722ddd5405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -2.32, p-value: 0.0227\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     0      1   5.2768 0.0227 0.7537 9.7998   True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=50)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores)\n",
    "print(f\"t-statistic: {t_stat:.2f}, p-value: {p_val:.4f}\")\n",
    "\n",
    "# Conduct post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(np.concatenate((control_scores, experimental_scores)),\n",
    "                                  np.concatenate(([0]*50, [1]*50)), alpha=0.05)\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d81b62-1a1d-49ba-b884-a8f80a8687f7",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a135aee5-a2ed-4520-9378-078abbc9cc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70/919142908.py:20: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  sales_long = pd.melt(sales_df, id_vars='Day', var_name='Stores', value_name='Sales')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Stores</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Stores</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stores</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Stores</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Stores</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Stores</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>29</td>\n",
       "      <td>Sales</td>\n",
       "      <td>109.140976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>29</td>\n",
       "      <td>Sales</td>\n",
       "      <td>112.67538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>30</td>\n",
       "      <td>Sales</td>\n",
       "      <td>107.874769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>30</td>\n",
       "      <td>Sales</td>\n",
       "      <td>140.871134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>30</td>\n",
       "      <td>Sales</td>\n",
       "      <td>121.644412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Stores       Sales\n",
       "0      1  Stores           A\n",
       "1      1  Stores           A\n",
       "2      1  Stores           A\n",
       "3      2  Stores           A\n",
       "4      2  Stores           A\n",
       "..   ...     ...         ...\n",
       "175   29   Sales  109.140976\n",
       "176   29   Sales   112.67538\n",
       "177   30   Sales  107.874769\n",
       "178   30   Sales  140.871134\n",
       "179   30   Sales  121.644412\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(123)\n",
    "store_a_sales = np.random.normal(loc=100, scale=10, size=30)\n",
    "store_b_sales = np.random.normal(loc=110, scale=10, size=30)\n",
    "store_c_sales = np.random.normal(loc=120, scale=10, size=30)\n",
    "\n",
    "sales_df = pd.DataFrame({'Stores': np.repeat(np.array([['A'],['B'],['C']]),[30,30,30]),\n",
    "                        'Sales':np.repeat([store_a_sales,store_b_sales,store_c_sales],1)})\n",
    "\n",
    "# Add a column for the day number\n",
    "sales_df['Day'] = np.repeat(range(1, 31), 3)\n",
    "\n",
    "# Reshape the data to long format\n",
    "sales_long = pd.melt(sales_df, id_vars='Day', var_name='Stores', value_name='Sales')\n",
    "sales_long\n",
    "# # Conduct repeated measures ANOVA\n",
    "# rm = AnovaRM(data=sales_long, depvar='Sales', subject='Stores', within=['Day'])\n",
    "# res = rm.fit()\n",
    "# print(res.summary())\n",
    "\n",
    "# # Conduct post-hoc test\n",
    "# tukey_results = pairwise_tukeyhsd(sales_long['Sales'], sales_long['Stores'], alpha=0.05)\n",
    "# print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8b4940-bb6f-4c5d-96cd-14899df4fd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stores</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>87.866152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>86.735122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>114.083691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>93.912892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>86.793974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>C</td>\n",
       "      <td>116.066891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>C</td>\n",
       "      <td>110.424182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>C</td>\n",
       "      <td>140.564673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>C</td>\n",
       "      <td>101.115076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>C</td>\n",
       "      <td>108.716695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stores       Sales\n",
       "0       A   87.866152\n",
       "1       A   86.735122\n",
       "2       A  114.083691\n",
       "3       A   93.912892\n",
       "4       A   86.793974\n",
       "..    ...         ...\n",
       "85      C  116.066891\n",
       "86      C  110.424182\n",
       "87      C  140.564673\n",
       "88      C  101.115076\n",
       "89      C  108.716695\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_a_sales = np.random.normal(loc=100, scale=10, size=30)\n",
    "store_b_sales = np.random.normal(loc=110, scale=10, size=30)\n",
    "store_c_sales = np.random.normal(loc=120, scale=10, size=30)\n",
    "\n",
    "\n",
    "# Create a data frame with the sales data\n",
    "# sales_df = pd.DataFrame({'Stores A': store_a_sales,\n",
    "#                          'Store B': store_b_sales,\n",
    "#                          'Store C': store_c_sales})\n",
    "\n",
    "sales_df = pd.DataFrame({'Stores': np.repeat(np.array([['A'],['B'],['C']]),[30,30,30]),\n",
    "                        'Sales':np.repeat([store_a_sales,store_b_sales,store_c_sales],1)})\n",
    "sales_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
